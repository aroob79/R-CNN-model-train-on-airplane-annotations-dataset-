{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt \n",
    "import matplotlib \n",
    "import os \n",
    "matplotlib.use('TKAgg')\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.applications.vgg16 import VGG16 \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras import callbacks \n",
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "from tensorflow.keras.callbacks import CSVLogger \n",
    "from sklearn.model_selection import train_test_split \n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import pickle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r'E:\\python\\basic code\\R-cNN\\Images'\n",
    "path1=r'E:\\python\\basic code\\R-cNN\\Airplanes_Annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generates bounding box \n",
    "img_data=cv2.imread(os.path.join(path,\"airplane_012.jpg\"))\n",
    "ss=cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "ss.setBaseImage(img_data)\n",
    "ss.switchToSelectiveSearchFast()\n",
    "rect=ss.process()\n",
    "for x,y,w,h in rect:\n",
    "    cv2.rectangle(img_data,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "    \n",
    "cv2.imshow('img',img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,h,w=rect[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_iou(gt,pred):\n",
    "    x1=max(gt[0],pred[0])\n",
    "    y1=max(gt[1],pred[1])\n",
    "    x2=min(gt[2],pred[2])\n",
    "    y2=min(gt[3],pred[3])\n",
    "    #calculating the area of the intersection region \n",
    "    width=max(0,x2-x1)\n",
    "    height=max(0,y2-y1)\n",
    "    intersection_area=(width+1)*(height+1)\n",
    "    total_area=(gt[2]-gt[0]+1)*(gt[3]-gt[1]+1)+((pred[2]-pred[0]+1)*(pred[3]-pred[1]+1))\n",
    "    iou=intersection_area/(total_area-intersection_area)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 29  12 123  98]\n",
      "[ 82 137 186 227]\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(os.path.join(path1,\"airplane_012.csv\"))\n",
    "for i in df.values:\n",
    "    x1,y1,x2,y2=i[0].split(\" \")\n",
    "    print(np.array([int(x1),int(y1),int(x2),int(y2)]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1=cv2.imread(os.path.join(path,\"airplane_012.jpg\"))\n",
    "plt.imshow(dt1[137:228,82:187])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n",
      "20 20\n"
     ]
    }
   ],
   "source": [
    "#finding the bounding box which has iou larger than 0.7 and smaller than 0.3\n",
    "ss=cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "train_img=[]\n",
    "train_label=[]\n",
    "for i,f in enumerate(os.listdir(path)):\n",
    "    if f.startswith('airplane'):\n",
    "        img_name=f.split('.')[0]\n",
    "        img_data=cv2.imread(os.path.join(path,f))\n",
    "        \n",
    "        \n",
    "        ss.setBaseImage(img_data)\n",
    "        ss.switchToSelectiveSearchFast()\n",
    "        rect=ss.process()\n",
    "        #corresponding dataframe\n",
    "        df=pd.read_csv(os.path.join(path1,img_name+\".csv\"))\n",
    "        img_copy=img_data.copy()\n",
    "        counter=0\n",
    "        bcounter=0\n",
    "        flag=0\n",
    "        fflag=0\n",
    "        bflag=0\n",
    "        for num,bbox in enumerate(rect):\n",
    "            if num<1000 and flag ==0 :\n",
    "                x,y,w,h=bbox\n",
    "                pred=[x,y,x+w,y+h]\n",
    "            \n",
    "                for box in df.values:\n",
    "                    x1,y1,x2,y2=box[0].split(\" \")\n",
    "                    gt=np.array([int(x1),int(y1),int(x2),int(y2)])\n",
    "                    \n",
    "                    #calculating the iou \n",
    "                    iou=cal_iou(gt,pred)\n",
    "                    \n",
    "                    if counter <20:\n",
    "                        if iou>0.7:\n",
    "                            temp_img=img_copy[y:y+h+1,x:x+w+1]\n",
    "                            resize_temp_img=cv2.resize(temp_img,(224,224),interpolation=cv2.INTER_AREA)\n",
    "                            train_img.append(resize_temp_img)\n",
    "                            # label the pic containing airplane as 1\n",
    "                            train_label.append(1)\n",
    "                            counter+=1\n",
    "                            \n",
    "                            \n",
    "                    else:\n",
    "                        fflag=1\n",
    "                        \n",
    "                    if bcounter<20:\n",
    "                        if iou<0.3:\n",
    "                            temp_img=img_copy[y:y+h+1,x:x+w+1]\n",
    "                            resize_temp_img=cv2.resize(temp_img,(224,224),interpolation=cv2.INTER_AREA)\n",
    "                            train_img.append(resize_temp_img)\n",
    "                            # label the background as 0 \n",
    "                            train_label.append(0)\n",
    "                            bcounter+=1\n",
    "                            \n",
    "                    else:\n",
    "                        bflag=1\n",
    "                        \n",
    "                if fflag ==1 and bflag ==1 :\n",
    "                    flag=1\n",
    "                    #print(counter,bcounter)\n",
    "                        \n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"image_data.pkl\",\"wb\") as file:\n",
    "    pickle.dump(train_img,file)\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"image_label.pkl\",\"wb\") as file:\n",
    "    pickle.dump(train_label,file)\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#lets randomly pick some of them and plot them \n",
    "rand_num=np.random.randint(0,len(train_label))\n",
    "plt.imshow(train_img[rand_num])\n",
    "print(train_label[rand_num])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img=np.array(train_img[:5000])\n",
    "train_label=np.array(train_label[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 224, 224, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.functional.Functional at 0x21f6b81f010>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first import the vdd16 model \n",
    "vgg_16=VGG16(weights='imagenet',include_top=True)\n",
    "vgg_16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 224, 224, 3) dtype=float32 (created by layer 'input_1')>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_16.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking the first 15 layer \n",
    "for layer in vgg_16.layers[:15]:\n",
    "    layer.trainable=False\n",
    "    \n",
    "#taking till the 2nd last layer \n",
    "vgg_model=vgg_16.layers[-2].output\n",
    "#lats define the last output layers \n",
    "prediction=keras.layers.Dense(units=2,activation=\"softmax\")(vgg_model)\n",
    "final_model=keras.Model(inputs=vgg_16.input,outputs=prediction,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 8194      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134268738 (512.19 MB)\n",
      "Trainable params: 126633474 (483.07 MB)\n",
      "Non-trainable params: 7635264 (29.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),loss=keras.losses.sparse_categorical_crossentropy,\n",
    "                    metrics=['accuracy'])\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback=callbacks.ModelCheckpoint(save_best_only=True,\n",
    "                                   filepath=\"best_rcnn.h5\",\n",
    "                                   verbose=2,\n",
    "                                   monitor='val_accuracy',\n",
    "                                   mode='max'\n",
    "                                   )\n",
    "es=EarlyStopping(monitor=\"val_accuracy\",min_delta=0.01,patience=5,verbose=2)\n",
    "csvlogger=CSVLogger(filename=\"r_cnn.csv\",append=True,separator=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting the data into train and test \n",
    "x_train,x_test,y_train,y_test=train_test_split(train_img,train_label,test_size=0.15,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traning the model \n",
    "#hist=final_model.fit(x_train,y_train,epochs=20,callbacks=[callback,es,csvlogger],validation_data=[x_test,y_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test data \n",
    "ss=cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "test_img=cv2.imread(os.path.join(path,\"428483.jpg\"))\n",
    "copy_test_img=test_img.copy()\n",
    "ss.setBaseImage(test_img)\n",
    "ss.switchToSelectiveSearchFast()\n",
    "rect=ss.process()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165, 4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246, 224, 224, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img_data=[]\n",
    "for e in rect:\n",
    "    x,y,w,h=e \n",
    "    temp_img=test_img[y:y+h+1,x:x+w+1] \n",
    "    temp_img=cv2.resize(temp_img,(224,224),interpolation = cv2.INTER_AREA)\n",
    "    test_img_data.append(temp_img)\n",
    "    \n",
    "test_img_data=np.array(test_img_data)\n",
    "test_img_data.shape\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with open(\"test_image_dat.pkl\",\"wb\") as file:\n",
    "    pickle.dump(test_img_data,file)\n",
    "    \n",
    "file.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 172s 22s/step\n"
     ]
    }
   ],
   "source": [
    "#best_model=load_model(os.path.join(r'E:\\python\\basic code\\R-cNN',\"best_rcnn.h5\"))\n",
    "prediction=best_model.predict(test_img_data)\n",
    "#y_pred=np.argmax(prediction[prediction[:,1] > 0.9],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66399586, 0.33600405],\n",
       "       [0.93973255, 0.06026752],\n",
       "       [0.87708676, 0.12291323],\n",
       "       ...,\n",
       "       [0.9931116 , 0.0068884 ],\n",
       "       [0.97275317, 0.02724688],\n",
       "       [0.98469365, 0.0153064 ]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img=cv2.imread(os.path.join(path,\"428483.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num,data in enumerate(prediction):\n",
    "    if data[1] > 0.80:\n",
    "        x,y,w,h=rect[num]\n",
    "        cv2.rectangle(test_img,(x,y),(x+w,y+h),(0,255,0),1,cv2.LINE_AA)\n",
    "        \n",
    "        \n",
    "plt.imshow(test_img)\n",
    "plt.show()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
